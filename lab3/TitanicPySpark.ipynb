{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Project done by SHUBHAM SHAILESH PANDEY, UBID - spandey4\n",
    "import time\n",
    "import pyspark\n",
    "import os\n",
    "import csv\n",
    "from numpy import array\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Spark environment\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"hdfs\"\n",
    "os.environ[\"PYTHON_VERSION\"] = \"3.5.2\"\n",
    "conf = pyspark.SparkConf()\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv MapPartitionsRDD[1] at textFile at <unknown>:0\n",
      "\n",
      "\n",
      "['1', '0', '3', 'Braund, Mr. Owen Harris', 'male', '22', '1', '0', 'A/5 21171', '7.25', '', 'S']\n",
      "\n",
      "\n",
      "[['0', '3', 0, '22', '1', '0', 'A/5 21171', '7.25', ''], ['1', '1', 1, '38', '1', '0', 'PC 17599', '71.2833', 'C85'], ['1', '3', 1, '26', '0', '0', 'STON/O2. 3101282', '7.925', ''], ['1', '1', 1, '35', '1', '0', '113803', '53.1', 'C123'], ['0', '3', 0, '35', '0', '0', '373450', '8.05', ''], ['0', '1', 0, '54', '0', '0', '17463', '51.8625', 'E46'], ['0', '3', 0, '2', '3', '1', '349909', '21.075', ''], ['1', '3', 1, '27', '0', '2', '347742', '11.1333', ''], ['1', '2', 1, '14', '1', '0', '237736', '30.0708', ''], ['1', '3', 1, '4', '1', '1', 'PP 9549', '16.7', 'G6']]\n",
      "\n",
      "\n",
      "Labeled data example-\n",
      "(0.0,[3.0,0.0,22.0,1.0])\n",
      "\n",
      "\n",
      "RF takes 8 s\n",
      "\n",
      "\n",
      "Area under PR = 0.7001270734839996\n",
      "Area under ROC = 0.8708439897698209\n"
     ]
    }
   ],
   "source": [
    "# Reading from the hdfs, removing the header\n",
    "trainTitanic = sc.textFile(\"train.csv\")\n",
    "print(trainTitanic)\n",
    "print(\"\\n\")\n",
    "trainHeader = trainTitanic.first()\n",
    "trainTitanic = trainTitanic.filter(lambda line: line != trainHeader).mapPartitions(lambda x: csv.reader(x))\n",
    "print(trainTitanic.first())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Data preprocessing\n",
    "def sexTransformMapper(elem):\n",
    "    '''Function which transform \"male\" into 1 and else things into 0\n",
    "    - elem : string\n",
    "    - return : vector\n",
    "    '''\n",
    "     \n",
    "    if elem == 'male' :\n",
    "        return [0]\n",
    "    else :\n",
    "        return [1]\n",
    "    \n",
    "\n",
    "# Data Transformations and filter lines with empty strings\n",
    "trainTitanic=trainTitanic.map(lambda line: line[1:3]+sexTransformMapper(line[4])+line[5:11])\n",
    "trainTitanic=trainTitanic.filter(lambda line: line[3] != '' ).filter(lambda line: line[4] != '' )\n",
    "print(trainTitanic.take(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# creating \"labeled point\" rdds specific to MLlib \"(label (v1, v2...vp])\"\n",
    "trainTitanicLP=trainTitanic.map(lambda line: LabeledPoint(line[0],[line[1:5]]))\n",
    "print(\"Labeled data example-\")\n",
    "print(trainTitanicLP.first())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# splitting dataset into train and test set\n",
    "(trainData, testData) = trainTitanicLP.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Random forest : same parameters as sklearn (?)\n",
    "from pyspark.mllib.tree import RandomForest\n",
    " \n",
    "time_start=time.time()\n",
    "model_rf = RandomForest.trainClassifier(trainData, numClasses = 2,\n",
    "        categoricalFeaturesInfo = {}, numTrees = 100,\n",
    "        featureSubsetStrategy='auto', impurity='gini', maxDepth=12,\n",
    "        maxBins=32, seed=None)\n",
    "model_rf.numTrees()\n",
    "model_rf.totalNumNodes()\n",
    "time_end=time.time()\n",
    "time_rf=(time_end - time_start)\n",
    "print(\"RF takes %d s\" %(time_rf))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Predictions on test set\n",
    "predictions = model_rf.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "\n",
    "# first metrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(labelsAndPredictions)\n",
    " \n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    " \n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    " \n",
    "# Creatingt Spark SQL environment\n",
    "from pyspark.sql import SparkSession, HiveContext\n",
    "SparkContext.setSystemProperty(\"hive.metastore.uris\", \"thrift://nn1:9083\")\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    " \n",
    "# spark is an existing SparkSession\n",
    "train = spark.read.csv(\"train.csv\", header = True)\n",
    "# Displays the content of the DataFrame to stdout\n",
    "print(train.show(10))\n",
    " \n",
    "# String to float on some columns of the dataset : creates a new dataset\n",
    "train = train.select(col(\"Survived\"),col(\"Sex\"),col(\"Embarked\"),col(\"Pclass\").cast(\"float\"),col(\"Age\").cast(\"float\"),col(\"SibSp\").cast(\"float\"),col(\"Fare\").cast(\"float\"))\n",
    " \n",
    "# dropping null values\n",
    "train = train.dropna()\n",
    " \n",
    "# Spliting in train and test set. Beware : It sorts the dataset\n",
    "(traindf, testdf) = train.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+------+----+-----+-------+----------+---------------+---------------+-------------+-------------+--------------------+\n",
      "|Survived|   Sex|Embarked|Pclass| Age|SibSp|   Fare|indexedSex|indexedEmbarked|indexedSurvived|       sexVec|  embarkedVec|            features|\n",
      "+--------+------+--------+------+----+-----+-------+----------+---------------+---------------+-------------+-------------+--------------------+\n",
      "|       0|  male|       S|   3.0|22.0|  1.0|   7.25|       0.0|            0.0|            0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,1.0,0.0,...|\n",
      "|       1|female|       C|   1.0|38.0|  1.0|71.2833|       1.0|            1.0|            1.0|    (1,[],[])|(2,[1],[1.0])|[1.0,0.0,0.0,1.0,...|\n",
      "|       1|female|       S|   3.0|26.0|  0.0|  7.925|       1.0|            0.0|            1.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,1.0,0.0,...|\n",
      "|       1|female|       S|   1.0|35.0|  1.0|   53.1|       1.0|            0.0|            1.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,1.0,0.0,...|\n",
      "|       0|  male|       S|   3.0|35.0|  0.0|   8.05|       0.0|            0.0|            0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,1.0,0.0,...|\n",
      "|       0|  male|       S|   1.0|54.0|  0.0|51.8625|       0.0|            0.0|            0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,1.0,0.0,...|\n",
      "|       0|  male|       S|   3.0| 2.0|  3.0| 21.075|       0.0|            0.0|            0.0|(1,[0],[1.0])|(2,[0],[1.0])|[3.0,1.0,1.0,0.0,...|\n",
      "|       1|female|       S|   3.0|27.0|  0.0|11.1333|       1.0|            0.0|            1.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,1.0,0.0,...|\n",
      "|       1|female|       C|   2.0|14.0|  1.0|30.0708|       1.0|            1.0|            1.0|    (1,[],[])|(2,[1],[1.0])|[2.0,0.0,0.0,1.0,...|\n",
      "|       1|female|       S|   3.0| 4.0|  1.0|   16.7|       1.0|            0.0|            1.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,1.0,0.0,...|\n",
      "+--------+------+--------+------+----+-----+-------+----------+---------------+---------------+-------------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n",
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.90576606599069...|\n",
      "|       1.0|[0.05473323906304...|\n",
      "|       0.0|[0.53835249272109...|\n",
      "|       1.0|[0.06145242943916...|\n",
      "|       0.0|[0.87013708198753...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "train = StringIndexer(inputCol=\"Sex\", outputCol=\"indexedSex\").fit(train).transform(train)\n",
    "train = StringIndexer(inputCol=\"Embarked\", outputCol=\"indexedEmbarked\").fit(train).transform(train)\n",
    " \n",
    "train = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedSurvived\").fit(train).transform(train)\n",
    " \n",
    "# One Hot Encoder on indexed features\n",
    "train = OneHotEncoder(inputCol=\"indexedSex\", outputCol=\"sexVec\").transform(train)\n",
    "train = OneHotEncoder(inputCol=\"indexedEmbarked\", outputCol=\"embarkedVec\").transform(train)\n",
    " \n",
    "# Feature assembler as a vector\n",
    "train = VectorAssembler(inputCols=[\"Pclass\",\"sexVec\",\"embarkedVec\", \"Age\",\"SibSp\",\"Fare\"],outputCol=\"features\").transform(train)\n",
    "print(train.show(10))\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"indexedSurvived\", featuresCol=\"features\")\n",
    " \n",
    "model = rf.fit(train)\n",
    " \n",
    "predictions = model.transform(train)\n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.select(col(\"prediction\"),col(\"probability\"),).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|(7,[0,2,4],[3.0,2...|\n",
      "|       1.0|       0|[1.0,0.0,2.0,1.0,...|\n",
      "|       1.0|       0|[2.0,0.0,44.0,1.0...|\n",
      "|       0.0|       0|[3.0,0.0,8.0,3.0,...|\n",
      "|       0.0|       0|[3.0,0.0,9.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.162679\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_4501a9358feebcf4cdfb) with 20 trees\n",
      "Accuracy = 0.837321\n",
      "f1 = 0.830646\n",
      "weightedPrecision = 0.84979\n",
      "weightedRecall = 0.837321\n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "genderIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"indexedSex\")\n",
    "embarkIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"indexedEmbarked\")\n",
    " \n",
    "surviveIndexer = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedSurvived\")\n",
    " \n",
    "# One Hot Encoder on indexed features\n",
    "genderEncoder = OneHotEncoder(inputCol=\"indexedSex\", outputCol=\"sexVec\")\n",
    "embarkEncoder = OneHotEncoder(inputCol=\"indexedEmbarked\", outputCol=\"embarkedVec\")\n",
    " \n",
    "# Create the vector structured data (label,features(vector))\n",
    "assembler = VectorAssembler(inputCols=[\"Pclass\",\"sexVec\",\"Age\",\"SibSp\",\"Fare\",\"embarkedVec\"],outputCol=\"features\")\n",
    " \n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedSurvived\", featuresCol=\"features\")\n",
    " \n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[surviveIndexer, genderIndexer, embarkIndexer, genderEncoder,embarkEncoder, assembler, rf]) # genderIndexer,embarkIndexer,genderEncoder,embarkEncoder,\n",
    " \n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(traindf)\n",
    " \n",
    "# Predictions\n",
    "predictions = model.transform(testdf)\n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.columns \n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
    " \n",
    "# Select (prediction, true label) and compute test error\n",
    "predictions = predictions.select(col(\"Survived\").cast(\"Float\"),col(\"prediction\"))\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    " \n",
    "rfModel = model.stages[6]\n",
    "print(rfModel)  # summary only\n",
    " \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    " \n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)\n",
    " \n",
    "# close sparkcontext\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
